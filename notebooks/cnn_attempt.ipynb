{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce 940MX'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/site-packages/ipykernel_launcher.py:17: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"import os\\nimport random\\nimport pandas as pd\\nimport numpy as np\\nimport parent_modules\\n\\nfrom sklearn.model_selection import train_test_split\\n\\n%load_ext autoreload\\n%load_ext nb_black\\n%autoreload 2\\n\\nfrom definitions import *\\n\\ndatasets = {\\n    \\\"posts\\\": pd.read_csv(\\n        os.path.join(DATA_DIR, \\\"posts.tsv\\\"), sep=\\\"\\\\t|\\\\t \\\", header=None\\n    ),\\n    \\\"test\\\": pd.read_csv(os.path.join(DATA_DIR, \\\"test.csv\\\"), header=None),\\n    \\\"train\\\": pd.read_csv(os.path.join(DATA_DIR, \\\"train.csv\\\"), header=None),\\n    \\\"users\\\": pd.read_csv(os.path.join(DATA_DIR, \\\"users.csv\\\")),\\n}\\ndatasets[\\\"posts\\\"].columns = [\\\"post_id\\\", \\\"user_id\\\", \\\"post\\\"]\\ndatasets[\\\"test\\\"].columns = [\\\"post_id\\\", \\\"label\\\"]\\ndatasets[\\\"train\\\"].columns = [\\\"post_id\\\", \\\"label\\\"]\\n\\n# print(datasets[\\\"posts\\\"].applymap(lambda x: str(x).strip()).head())\\n\\n\\ntrain_ids = datasets[\\\"train\\\"][\\\"post_id\\\"]\\ntest_ids = datasets[\\\"test\\\"][\\\"post_id\\\"]\\ntrain_posts = datasets[\\\"posts\\\"][datasets[\\\"posts\\\"].post_id.isin(list(train_ids))].post\\ndatasets[\\\"train\\\"].insert(2, \\\"post\\\", list(train_posts))\\ntests_posts = datasets[\\\"posts\\\"][datasets[\\\"posts\\\"].post_id.isin(list(test_ids))].post\\ndatasets[\\\"test\\\"].insert(2, \\\"post\\\", list(tests_posts))\\n\\nflair_full_train = datasets[\\\"train\\\"].copy(deep=True)\\nflair_full_train[\\\"label\\\"] = \\\"__label__\\\" + datasets[\\\"train\\\"][\\\"label\\\"].astype(str)\\nflair_full_train[\\\"label\\\"] = pd.Categorical(flair_full_train.label)\\n\\n# split trainset to dev and train\\nflair_train, flair_test = train_test_split(\\n    flair_full_train,\\n    test_size=0.2,\\n    random_state=np.random.RandomState(12),\\n    stratify=flair_full_train[\\\"label\\\"],\\n)\\nflair_dev, flair_test = train_test_split(\\n    flair_test,\\n    test_size=0.5,\\n    random_state=np.random.RandomState(12),\\n    stratify=flair_test[\\\"label\\\"],\\n)\\n\\n\\n# save as_csv\\nflair_train.to_csv(\\n    os.path.join(FLAIR_DATA_DIR, \\\"flair_train.csv\\\"),\\n    sep=\\\"\\\\t\\\",\\n    index=False,\\n    header=False,\\n    columns=[\\\"label\\\", \\\"post\\\"],\\n)\\nflair_dev.to_csv(\\n    os.path.join(FLAIR_DATA_DIR, \\\"flair_dev.csv\\\"),\\n    sep=\\\"\\\\t\\\",\\n    index=False,\\n    header=False,\\n    columns=[\\\"label\\\", \\\"post\\\"],\\n)\\nflair_test.to_csv(\\n    os.path.join(FLAIR_DATA_DIR, \\\"flair_test.csv\\\"),\\n    sep=\\\"\\\\t\\\",\\n    index=False,\\n    header=False,\\n    columns=[\\\"label\\\", \\\"post\\\"],\\n)\";\n",
       "                var nbb_formatted_code = \"import os\\nimport random\\nimport pandas as pd\\nimport numpy as np\\nimport parent_modules\\n\\nfrom sklearn.model_selection import train_test_split\\n\\n%load_ext autoreload\\n%load_ext nb_black\\n%autoreload 2\\n\\nfrom definitions import *\\n\\ndatasets = {\\n    \\\"posts\\\": pd.read_csv(\\n        os.path.join(DATA_DIR, \\\"posts.tsv\\\"), sep=\\\"\\\\t|\\\\t \\\", header=None\\n    ),\\n    \\\"test\\\": pd.read_csv(os.path.join(DATA_DIR, \\\"test.csv\\\"), header=None),\\n    \\\"train\\\": pd.read_csv(os.path.join(DATA_DIR, \\\"train.csv\\\"), header=None),\\n    \\\"users\\\": pd.read_csv(os.path.join(DATA_DIR, \\\"users.csv\\\")),\\n}\\ndatasets[\\\"posts\\\"].columns = [\\\"post_id\\\", \\\"user_id\\\", \\\"post\\\"]\\ndatasets[\\\"test\\\"].columns = [\\\"post_id\\\", \\\"label\\\"]\\ndatasets[\\\"train\\\"].columns = [\\\"post_id\\\", \\\"label\\\"]\\n\\n# print(datasets[\\\"posts\\\"].applymap(lambda x: str(x).strip()).head())\\n\\n\\ntrain_ids = datasets[\\\"train\\\"][\\\"post_id\\\"]\\ntest_ids = datasets[\\\"test\\\"][\\\"post_id\\\"]\\ntrain_posts = datasets[\\\"posts\\\"][datasets[\\\"posts\\\"].post_id.isin(list(train_ids))].post\\ndatasets[\\\"train\\\"].insert(2, \\\"post\\\", list(train_posts))\\ntests_posts = datasets[\\\"posts\\\"][datasets[\\\"posts\\\"].post_id.isin(list(test_ids))].post\\ndatasets[\\\"test\\\"].insert(2, \\\"post\\\", list(tests_posts))\\n\\nflair_full_train = datasets[\\\"train\\\"].copy(deep=True)\\nflair_full_train[\\\"label\\\"] = \\\"__label__\\\" + datasets[\\\"train\\\"][\\\"label\\\"].astype(str)\\nflair_full_train[\\\"label\\\"] = pd.Categorical(flair_full_train.label)\\n\\n# split trainset to dev and train\\nflair_train, flair_test = train_test_split(\\n    flair_full_train,\\n    test_size=0.2,\\n    random_state=np.random.RandomState(12),\\n    stratify=flair_full_train[\\\"label\\\"],\\n)\\nflair_dev, flair_test = train_test_split(\\n    flair_test,\\n    test_size=0.5,\\n    random_state=np.random.RandomState(12),\\n    stratify=flair_test[\\\"label\\\"],\\n)\\n\\n\\n# save as_csv\\nflair_train.to_csv(\\n    os.path.join(FLAIR_DATA_DIR, \\\"flair_train.csv\\\"),\\n    sep=\\\"\\\\t\\\",\\n    index=False,\\n    header=False,\\n    columns=[\\\"label\\\", \\\"post\\\"],\\n)\\nflair_dev.to_csv(\\n    os.path.join(FLAIR_DATA_DIR, \\\"flair_dev.csv\\\"),\\n    sep=\\\"\\\\t\\\",\\n    index=False,\\n    header=False,\\n    columns=[\\\"label\\\", \\\"post\\\"],\\n)\\nflair_test.to_csv(\\n    os.path.join(FLAIR_DATA_DIR, \\\"flair_test.csv\\\"),\\n    sep=\\\"\\\\t\\\",\\n    index=False,\\n    header=False,\\n    columns=[\\\"label\\\", \\\"post\\\"],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import parent_modules\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext autoreload\n",
    "%load_ext nb_black\n",
    "%autoreload 2\n",
    "\n",
    "from definitions import *\n",
    "\n",
    "datasets = {\n",
    "    \"posts\": pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"posts.tsv\"), sep=\"\\t|\\t \", header=None\n",
    "    ),\n",
    "    \"test\": pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"), header=None),\n",
    "    \"train\": pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"), header=None),\n",
    "    \"users\": pd.read_csv(os.path.join(DATA_DIR, \"users.csv\")),\n",
    "}\n",
    "datasets[\"posts\"].columns = [\"post_id\", \"user_id\", \"post\"]\n",
    "datasets[\"test\"].columns = [\"post_id\", \"label\"]\n",
    "datasets[\"train\"].columns = [\"post_id\", \"label\"]\n",
    "\n",
    "# print(datasets[\"posts\"].applymap(lambda x: str(x).strip()).head())\n",
    "\n",
    "\n",
    "train_ids = datasets[\"train\"][\"post_id\"]\n",
    "test_ids = datasets[\"test\"][\"post_id\"]\n",
    "train_posts = datasets[\"posts\"][datasets[\"posts\"].post_id.isin(list(train_ids))].post\n",
    "datasets[\"train\"].insert(2, \"post\", list(train_posts))\n",
    "tests_posts = datasets[\"posts\"][datasets[\"posts\"].post_id.isin(list(test_ids))].post\n",
    "datasets[\"test\"].insert(2, \"post\", list(tests_posts))\n",
    "\n",
    "flair_full_train = datasets[\"train\"].copy(deep=True)\n",
    "flair_full_train[\"label\"] = \"__label__\" + datasets[\"train\"][\"label\"].astype(str)\n",
    "# flair_full_train[\"label\"] = pd.Categorical(flair_full_train.label)\n",
    "\n",
    "# split trainset to dev and train\n",
    "flair_train, flair_test = train_test_split(\n",
    "    flair_full_train,\n",
    "    test_size=0.2,\n",
    "    random_state=np.random.RandomState(12),\n",
    "    stratify=flair_full_train[\"label\"],\n",
    ")\n",
    "flair_dev, flair_test = train_test_split(\n",
    "    flair_test,\n",
    "    test_size=0.5,\n",
    "    random_state=np.random.RandomState(12),\n",
    "    stratify=flair_test[\"label\"],\n",
    ")\n",
    "\n",
    "\n",
    "# save as_csv\n",
    "flair_train.to_csv(\n",
    "    os.path.join(FLAIR_DATA_DIR, \"flair_train.csv\"),\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    "    header=False,\n",
    "    columns=[\"label\", \"post\"],\n",
    ")\n",
    "flair_dev.to_csv(\n",
    "    os.path.join(FLAIR_DATA_DIR, \"flair_dev.csv\"),\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    "    header=False,\n",
    "    columns=[\"label\", \"post\"],\n",
    ")\n",
    "flair_test.to_csv(\n",
    "    os.path.join(FLAIR_DATA_DIR, \"flair_test.csv\"),\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    "    header=False,\n",
    "    columns=[\"label\", \"post\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>label</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>6768</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>@PaulineHansonOz @SamClench @newscomauHQ #coro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10350</th>\n",
       "      <td>12924</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>US death toll is way less than estimated. This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>3510</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>Please check out https://t.co/NebOqVR5Ib @TheR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7336</th>\n",
       "      <td>9118</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>Riverside County Public Health recommend all c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12526</th>\n",
       "      <td>15663</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>Another member of Government sent to Covid Cov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id       label                                               post\n",
       "5434      6768  __label__1  @PaulineHansonOz @SamClench @newscomauHQ #coro...\n",
       "10350    12924  __label__2  US death toll is way less than estimated. This...\n",
       "2828      3510  __label__0  Please check out https://t.co/NebOqVR5Ib @TheR...\n",
       "7336      9118  __label__0  Riverside County Public Health recommend all c...\n",
       "12526    15663  __label__0  Another member of Government sent to Covid Cov..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"flair_test.head()\";\n",
       "                var nbb_formatted_code = \"flair_test.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flair_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flair Load Embeddings\n",
    "\n",
    "### Instractions\n",
    "> In case you haven't download the used embeddings then click on the below links and place them in the *data/flair_files/* folder\n",
    "\n",
    "#### Twitter Embeddings\n",
    "1. https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/twitter.gensim.vectors.npy\n",
    "2. https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/twitter.gensim\n",
    "\n",
    "#### News Forward English\n",
    "1. https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n",
    "\n",
    "#### News Backward English\n",
    "1. https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n",
    "\n",
    "#### Glove\n",
    "1. https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy\n",
    "2. https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"from flair.embeddings import (\\n    StackedEmbeddings,\\n    DocumentLSTMEmbeddings,\\n    WordEmbeddings,\\n    FlairEmbeddings,\\n)\\nfrom flair.datasets import ClassificationCorpus\\nfrom flair.models import TextClassifier\\nfrom flair.trainers import ModelTrainer\\nfrom flair.data import Sentence\\n\\noutput_folder = os.path.join(FLAIR_OUTPUT_DIR, \\\"rnn_flair_basic\\\")\\nnew_model_folder = os.path.join(FLAIR_OUTPUT_DIR, \\\"flair_training_model\\\")\";\n",
       "                var nbb_formatted_code = \"from flair.embeddings import (\\n    StackedEmbeddings,\\n    DocumentLSTMEmbeddings,\\n    WordEmbeddings,\\n    FlairEmbeddings,\\n)\\nfrom flair.datasets import ClassificationCorpus\\nfrom flair.models import TextClassifier\\nfrom flair.trainers import ModelTrainer\\nfrom flair.data import Sentence\\n\\noutput_folder = os.path.join(FLAIR_OUTPUT_DIR, \\\"rnn_flair_basic\\\")\\nnew_model_folder = os.path.join(FLAIR_OUTPUT_DIR, \\\"flair_training_model\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from flair.embeddings import (\n",
    "    StackedEmbeddings,\n",
    "    DocumentLSTMEmbeddings,\n",
    "    WordEmbeddings,\n",
    "    FlairEmbeddings,\n",
    ")\n",
    "from flair.datasets import ClassificationCorpus\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.data import Sentence\n",
    "\n",
    "output_folder = os.path.join(FLAIR_OUTPUT_DIR, \"rnn_flair_basic\")\n",
    "new_model_folder = os.path.join(FLAIR_OUTPUT_DIR, \"flair_training_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-15 01:34:32,443 Reading data from /home/giannhs/PycharmProjects/data_challenge/data/flair_data_dir\n",
      "2020-06-15 01:34:32,443 Train: /home/giannhs/PycharmProjects/data_challenge/data/flair_data_dir/flair_train.csv\n",
      "2020-06-15 01:34:32,444 Dev: /home/giannhs/PycharmProjects/data_challenge/data/flair_data_dir/flair_dev.csv\n",
      "2020-06-15 01:34:32,445 Test: /home/giannhs/PycharmProjects/data_challenge/data/flair_data_dir/flair_test.csv\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"word_embeddings = [\\n    #     WordEmbeddings(os.path.join(FLAIR_EMDG_DIR, \\\"twitter.gensim\\\")),\\n    #     WordEmbeddings(os.path.join(FLAIR_EMDG_DIR, \\\"glove.gensim\\\")),\\n    FlairEmbeddings(\\n        os.path.join(FLAIR_EMDG_DIR, \\\"lm-news-english-forward-1024-v0.2rc.pt\\\")\\n    ),\\n    FlairEmbeddings(\\n        os.path.join(FLAIR_EMDG_DIR, \\\"lm-news-english-backward-1024-v0.2rc.pt\\\")\\n    ),\\n]\\n\\n# word_embeddings = [\\n#     WordEmbeddings(\\\"glove\\\"),\\n#     FlairEmbeddings(\\\"news-forward-fast\\\"),\\n#     FlairEmbeddings(\\\"news-backward-fast\\\"),\\n# ]\\n\\ncorpus = ClassificationCorpus(\\n    FLAIR_DATA_DIR,\\n    test_file=\\\"flair_test.csv\\\",\\n    dev_file=\\\"flair_dev.csv\\\",\\n    train_file=\\\"flair_train.csv\\\",\\n)\";\n",
       "                var nbb_formatted_code = \"word_embeddings = [\\n    #     WordEmbeddings(os.path.join(FLAIR_EMDG_DIR, \\\"twitter.gensim\\\")),\\n    #     WordEmbeddings(os.path.join(FLAIR_EMDG_DIR, \\\"glove.gensim\\\")),\\n    FlairEmbeddings(\\n        os.path.join(FLAIR_EMDG_DIR, \\\"lm-news-english-forward-1024-v0.2rc.pt\\\")\\n    ),\\n    FlairEmbeddings(\\n        os.path.join(FLAIR_EMDG_DIR, \\\"lm-news-english-backward-1024-v0.2rc.pt\\\")\\n    ),\\n]\\n\\n# word_embeddings = [\\n#     WordEmbeddings(\\\"glove\\\"),\\n#     FlairEmbeddings(\\\"news-forward-fast\\\"),\\n#     FlairEmbeddings(\\\"news-backward-fast\\\"),\\n# ]\\n\\ncorpus = ClassificationCorpus(\\n    FLAIR_DATA_DIR,\\n    test_file=\\\"flair_test.csv\\\",\\n    dev_file=\\\"flair_dev.csv\\\",\\n    train_file=\\\"flair_train.csv\\\",\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_embeddings = [\n",
    "    #     WordEmbeddings(os.path.join(FLAIR_EMDG_DIR, \"twitter.gensim\")),\n",
    "    #     WordEmbeddings(os.path.join(FLAIR_EMDG_DIR, \"glove.gensim\")),\n",
    "    FlairEmbeddings(\n",
    "        os.path.join(FLAIR_EMDG_DIR, \"lm-news-english-forward-1024-v0.2rc.pt\")\n",
    "    ),\n",
    "    FlairEmbeddings(\n",
    "        os.path.join(FLAIR_EMDG_DIR, \"lm-news-english-backward-1024-v0.2rc.pt\")\n",
    "    ),\n",
    "]\n",
    "\n",
    "# word_embeddings = [\n",
    "#     WordEmbeddings(\"glove\"),\n",
    "#     FlairEmbeddings(\"news-forward-fast\"),\n",
    "#     FlairEmbeddings(\"news-backward-fast\"),\n",
    "# ]\n",
    "\n",
    "corpus = ClassificationCorpus(\n",
    "    FLAIR_DATA_DIR,\n",
    "    test_file=\"flair_test.csv\",\n",
    "    dev_file=\"flair_dev.csv\",\n",
    "    train_file=\"flair_train.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-15 01:34:35,605 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated method __init__. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
      "  \"\"\"\n",
      "100%|██████████| 11898/11898 [00:06<00:00, 1819.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-15 01:34:42,259 [b'0', b'4', b'10', b'2', b'3', b'8', b'1', b'14', b'5', b'12', b'13', b'7', b'11', b'9', b'6']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"document_embeddings = DocumentLSTMEmbeddings(\\n    word_embeddings,\\n    hidden_size=512,\\n    reproject_words=True,\\n    reproject_words_dimension=256,\\n)\\nclassifier = TextClassifier(\\n    document_embeddings,\\n    label_dictionary=corpus.make_label_dictionary(),\\n    multi_label=True,\\n)\";\n",
       "                var nbb_formatted_code = \"document_embeddings = DocumentLSTMEmbeddings(\\n    word_embeddings,\\n    hidden_size=512,\\n    reproject_words=True,\\n    reproject_words_dimension=256,\\n)\\nclassifier = TextClassifier(\\n    document_embeddings,\\n    label_dictionary=corpus.make_label_dictionary(),\\n    multi_label=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_embeddings = DocumentLSTMEmbeddings(\n",
    "    word_embeddings,\n",
    "    hidden_size=512,\n",
    "    reproject_words=True,\n",
    "    reproject_words_dimension=256,\n",
    ")\n",
    "classifier = TextClassifier(\n",
    "    document_embeddings,\n",
    "    label_dictionary=corpus.make_label_dictionary(),\n",
    "    multi_label=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training  with basic parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-15 01:34:47,192 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-15 01:34:47,193 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentLSTMEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2048, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=15, bias=True)\n",
      "  (loss_function): BCEWithLogitsLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-06-15 01:34:47,193 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-15 01:34:47,194 Corpus: \"Corpus: 10575 train + 1322 dev + 1323 test sentences\"\n",
      "2020-06-15 01:34:47,195 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-15 01:34:47,198 Parameters:\n",
      "2020-06-15 01:34:47,203  - learning_rate: \"0.1\"\n",
      "2020-06-15 01:34:47,204  - mini_batch_size: \"32\"\n",
      "2020-06-15 01:34:47,205  - patience: \"3\"\n",
      "2020-06-15 01:34:47,206  - anneal_factor: \"0.5\"\n",
      "2020-06-15 01:34:47,207  - max_epochs: \"10\"\n",
      "2020-06-15 01:34:47,208  - shuffle: \"True\"\n",
      "2020-06-15 01:34:47,209  - train_with_dev: \"False\"\n",
      "2020-06-15 01:34:47,210  - batch_growth_annealing: \"False\"\n",
      "2020-06-15 01:34:47,213 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-15 01:34:47,214 Model training base path: \"/home/giannhs/PycharmProjects/data_challenge/data/flair_output_dir\"\n",
      "2020-06-15 01:34:47,215 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-15 01:34:47,216 Device: cuda:0\n",
      "2020-06-15 01:34:47,217 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-15 01:34:47,217 Embeddings storage mode: cpu\n",
      "2020-06-15 01:34:47,219 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-9:\n",
      "Process Process-12:\n",
      "Process Process-10:\n",
      "Process Process-11:\n",
      "Process Process-14:\n",
      "Process Process-13:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-15 01:35:15,602 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-15 01:35:15,607 Exiting from training early.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-15 01:35:15,608 Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f09723a6a70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 962, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 942, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/home/giannhs/miniconda3/envs/data_challenge/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-15 01:35:15,943 Done.\n",
      "2020-06-15 01:35:15,945 ----------------------------------------------------------------------------------------------------\n",
      "2020-06-15 01:35:15,947 Testing using best model ...\n"
     ]
    }
   ],
   "source": [
    "trainer = ModelTrainer(classifier, corpus)\n",
    "trainer.train(FLAIR_OUTPUT_DIR, max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load already trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = TextClassifier.load(os.path.join(output_folder, \"best-model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for test_post in list(datasets[\"test\"].post)[:10]:\n",
    "\n",
    "    sentence = Sentence(test_post)\n",
    "    res = classifier.predict(sentence)\n",
    "    print(res)\n",
    "    predictions.append(sentence.labels)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
