{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification of StackOverflow using BiGRU RNNs with deep self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"%load_ext autoreload\\n%load_ext nb_black\\n%autoreload 2\\n\\nimport sys\\nimport os\\nimport parent_modules\\n\\nimport warnings\\nimport sklearn.exceptions\\nimport talos as ta\\n\\nfrom os import pardir, getcwd\\nfrom os.path import join, abspath\\nfrom definitions import *\\n\\nwarnings.filterwarnings(\\\"ignore\\\", category=sklearn.exceptions.UndefinedMetricWarning)\\nwarnings.simplefilter(action=\\\"ignore\\\", category=FutureWarning)\\n\\nfrom definitions import TALOS_DIR\\nfrom app.preprocessing import (\\n    load_dataset,\\n    load_embeddings,\\n    preprocess_data,\\n    save_embeddings_matrix,\\n)\\nfrom app.models import load_bi_gru_model, find_best_model_over_scan_logs\\nfrom app.metrics import *\\n\\n# Comment out In case of Testing use only a set of the tags as dataset\\nRUN_STATE = \\\"testing\\\"\\n\\n# Comment out In case of Production use all the tags of the dataset\\n# RUN_STATE = 'production'\";\n",
       "                var nbb_formatted_code = \"%load_ext autoreload\\n%load_ext nb_black\\n%autoreload 2\\n\\nimport sys\\nimport os\\nimport parent_modules\\n\\nimport warnings\\nimport sklearn.exceptions\\nimport talos as ta\\n\\nfrom os import pardir, getcwd\\nfrom os.path import join, abspath\\nfrom definitions import *\\n\\nwarnings.filterwarnings(\\\"ignore\\\", category=sklearn.exceptions.UndefinedMetricWarning)\\nwarnings.simplefilter(action=\\\"ignore\\\", category=FutureWarning)\\n\\nfrom definitions import TALOS_DIR\\nfrom app.preprocessing import (\\n    load_dataset,\\n    load_embeddings,\\n    preprocess_data,\\n    save_embeddings_matrix,\\n)\\nfrom app.models import load_bi_gru_model, find_best_model_over_scan_logs\\nfrom app.metrics import *\\n\\n# Comment out In case of Testing use only a set of the tags as dataset\\nRUN_STATE = \\\"testing\\\"\\n\\n# Comment out In case of Production use all the tags of the dataset\\n# RUN_STATE = 'production'\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext nb_black\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import parent_modules\n",
    "\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "import talos as ta\n",
    "\n",
    "from os import pardir, getcwd\n",
    "from os.path import join, abspath\n",
    "from definitions import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "from definitions import TALOS_DIR\n",
    "from app.preprocessing import (\n",
    "    load_dataset,\n",
    "    load_embeddings,\n",
    "    preprocess_data,\n",
    "    save_embeddings_matrix,\n",
    ")\n",
    "from app.models import load_bi_gru_model, find_best_model_over_scan_logs\n",
    "from app.metrics import *\n",
    "\n",
    "# Comment out In case of Testing use only a set of the tags as dataset\n",
    "RUN_STATE = \"testing\"\n",
    "\n",
    "# Comment out In case of Production use all the tags of the dataset\n",
    "# RUN_STATE = 'production'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for the loaded Dataset\n",
    "1. Format into *lowercase*\n",
    "2. Remove some of the *punctuation* characters\n",
    "3. Remove *Numbers*\n",
    "4. Remove *stopwords*\n",
    "5. Remove *links*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__0     5622\n",
      "__label__2     2377\n",
      "__label__3     1400\n",
      "__label__4     1065\n",
      "__label__1      573\n",
      "__label__10     501\n",
      "__label__14     326\n",
      "__label__11     324\n",
      "__label__12     299\n",
      "__label__13     207\n",
      "__label__5      180\n",
      "__label__8      122\n",
      "__label__9      113\n",
      "__label__6       94\n",
      "__label__7       18\n",
      "Name: label, dtype: int64 ['__label__0', '__label__2', '__label__3', '__label__4', '__label__1', '__label__10', '__label__14', '__label__11', '__label__12', '__label__13', '__label__5', '__label__8', '__label__9', '__label__6', '__label__7'] 15\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"data, test_data = load_dataset(load_from_pickle=False)\\nclasses_counts = data[\\\"label\\\"].value_counts().where(lambda cls: cls > 0).dropna()\\nClasses = list(classes_counts.index)\\nNclasses = len(Classes)\\nprint(classes_counts, Classes, Nclasses)\";\n",
       "                var nbb_formatted_code = \"data, test_data = load_dataset(load_from_pickle=False)\\nclasses_counts = data[\\\"label\\\"].value_counts().where(lambda cls: cls > 0).dropna()\\nClasses = list(classes_counts.index)\\nNclasses = len(Classes)\\nprint(classes_counts, Classes, Nclasses)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data, test_data = load_dataset(load_from_pickle=True)\n",
    "classes_counts = data[\"label\"].value_counts().where(lambda cls: cls > 0).dropna()\n",
    "Classes = list(classes_counts.index)\n",
    "Nclasses = len(Classes)\n",
    "print(classes_counts, Classes, Nclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# 70% Train & 30% Test\\n# 70% Train-Dev % 30* Train-Dev\\nembeddings_voc, embeddings_vec = load_embeddings(load_from_pickle=True)\\nmodel_data = preprocess_data(data, \\\"label\\\", \\\"post\\\", cv_split_dev=0.2)\\nembeddings_matrix_path = save_embeddings_matrix(\\n    embeddings_voc, embeddings_vec, model_data[\\\"words_index\\\"]\\n)\";\n",
       "                var nbb_formatted_code = \"# 70% Train & 30% Test\\n# 70% Train-Dev % 30* Train-Dev\\nembeddings_voc, embeddings_vec = load_embeddings(load_from_pickle=True)\\nmodel_data = preprocess_data(data, \\\"label\\\", \\\"post\\\", cv_split_dev=0.2)\\nembeddings_matrix_path = save_embeddings_matrix(\\n    embeddings_voc, embeddings_vec, model_data[\\\"words_index\\\"]\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 70% Train & 30% Test\n",
    "# 70% Train-Dev % 30* Train-Dev\n",
    "embeddings_voc, embeddings_vec = load_embeddings(load_from_pickle=True)\n",
    "model_data = preprocess_data(data, \"label\", \"post\", cv_split_dev=0.2)\n",
    "embeddings_matrix_path = save_embeddings_matrix(\n",
    "    embeddings_voc, embeddings_vec, model_data[\"words_index\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5377,  7020,  3288,  7021, 10777,   388,   941,    54,   198,\n",
       "          80, 10778,     2,  2631,     2,     3, 10779,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"model_data[\\\"x_train\\\"][1]\";\n",
       "                var nbb_formatted_code = \"model_data[\\\"x_train\\\"][1]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_data[\"x_train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Definition and Hyperparameter Tuning\n",
    "\n",
    "> Below it will be defined, trained and evaluate the 2 models of RNNs the first with a unistack RNN with BiGRU and MLP on top of it and the second with a multistack RNN with BiGRU and MLP on top of it. \n",
    "The hyperparameter tuning is implemented throw the Talos library and will calculate the best configuration for each of the 2 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unistacked RNN with BiGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"###### Production configuration\\nrnn_deep_gru_config = {\\n    \\\"model_type\\\": [\\\"keras_deep_BiGRU_model\\\"],\\n    \\\"embedding_dim\\\": [embeddings_vec.shape[1]],\\n    \\\"gru_size\\\": [200],\\n    \\\"dense\\\": [300],\\n    \\\"embeddings_matrix_path\\\": [embeddings_matrix_path],\\n    \\\"visualize_process\\\": [True],\\n    \\\"with_early_stoping\\\": [True],\\n    \\\"multistack_run\\\": [False],\\n    'early_stopping':[True],\\n    'early_stopping_config__monitor': ['val_f1'],\\n    'early_stopping_config__min_delta': [0],\\n    'early_stopping_config__patience': [5],\\n    'early_stopping_config__mode': ['max'],\\n    \\\"embeddings_dropout\\\": [0.2],\\n    \\\"var_dropout\\\": [0.2, 0.6],\\n    \\\"mlp_dropout\\\": [0.2],\\n    \\\"mlp_activation\\\": [\\\"softmax\\\"],\\n    \\\"rnn_activation\\\": [\\\"relu\\\", \\\"tanh\\\"],\\n    \\\"optimizer\\\": [\\\"Nadam\\\", \\\"Adam\\\"],\\n    \\\"batch_size\\\": [32, 64],\\n    \\\"epochs\\\": [3 if RUN_STATE == 'testing' else 10]\\n}\";\n",
       "                var nbb_formatted_code = \"###### Production configuration\\nrnn_deep_gru_config = {\\n    \\\"model_type\\\": [\\\"keras_deep_BiGRU_model\\\"],\\n    \\\"embedding_dim\\\": [embeddings_vec.shape[1]],\\n    \\\"gru_size\\\": [200],\\n    \\\"dense\\\": [300],\\n    \\\"embeddings_matrix_path\\\": [embeddings_matrix_path],\\n    \\\"visualize_process\\\": [True],\\n    \\\"with_early_stoping\\\": [True],\\n    \\\"multistack_run\\\": [False],\\n    \\\"early_stopping\\\": [True],\\n    \\\"early_stopping_config__monitor\\\": [\\\"val_f1\\\"],\\n    \\\"early_stopping_config__min_delta\\\": [0],\\n    \\\"early_stopping_config__patience\\\": [5],\\n    \\\"early_stopping_config__mode\\\": [\\\"max\\\"],\\n    \\\"embeddings_dropout\\\": [0.2],\\n    \\\"var_dropout\\\": [0.2, 0.6],\\n    \\\"mlp_dropout\\\": [0.2],\\n    \\\"mlp_activation\\\": [\\\"softmax\\\"],\\n    \\\"rnn_activation\\\": [\\\"relu\\\", \\\"tanh\\\"],\\n    \\\"optimizer\\\": [\\\"Nadam\\\", \\\"Adam\\\"],\\n    \\\"batch_size\\\": [32, 64],\\n    \\\"epochs\\\": [3 if RUN_STATE == \\\"testing\\\" else 10],\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### Production configuration\n",
    "rnn_deep_gru_config = {\n",
    "    \"model_type\": [\"keras_deep_BiGRU_model\"],\n",
    "    \"embedding_dim\": [embeddings_vec.shape[1]],\n",
    "    \"gru_size\": [200],\n",
    "    \"dense\": [300],\n",
    "    \"embeddings_matrix_path\": [embeddings_matrix_path],\n",
    "    \"visualize_process\": [True],\n",
    "    \"with_early_stoping\": [True],\n",
    "    \"multistack_run\": [False],\n",
    "    \"early_stopping\": [True],\n",
    "    \"early_stopping_config__monitor\": [\"val_f1\"],\n",
    "    \"early_stopping_config__min_delta\": [0],\n",
    "    \"early_stopping_config__patience\": [5],\n",
    "    \"early_stopping_config__mode\": [\"max\"],\n",
    "    \"embeddings_dropout\": [0.2],\n",
    "    \"var_dropout\": [0.2, 0.6],\n",
    "    \"mlp_dropout\": [0.2],\n",
    "    \"mlp_activation\": [\"softmax\"],\n",
    "    \"rnn_activation\": [\"relu\", \"tanh\"],\n",
    "    \"optimizer\": [\"Nadam\", \"Adam\"],\n",
    "    \"batch_size\": [32, 64],\n",
    "    \"epochs\": [3 if RUN_STATE == \"testing\" else 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: './talos_logs/talos_bigru_deep_log_test/061520020559.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-8fabaa9eed3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mprint_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                         \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                         \u001b[0mexperiment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTALOS_BiGRU_DEEP_LOG_FILENAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                         )\n",
      "\u001b[0;32m~/miniconda3/envs/data_challenge/lib/python3.7/site-packages/talos/scan/Scan.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, params, model, experiment_name, x_val, y_val, val_split, random_method, seed, performance_target, fraction_limit, round_limit, time_limit, boolean_limit, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, minimize_loss, disable_progress_bar, print_params, clear_session, save_weights)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# start runtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscan_run\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscan_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mscan_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/data_challenge/lib/python3.7/site-packages/talos/scan/scan_run.py\u001b[0m in \u001b[0;36mscan_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscan_prepare\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscan_prepare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# initiate the progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data_challenge/lib/python3.7/site-packages/talos/scan/scan_prepare.py\u001b[0m in \u001b[0;36mscan_prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscan_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitialize_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# for the case where x_val or y_val is missing when other is present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data_challenge/lib/python3.7/site-packages/talos/scan/scan_utils.py\u001b[0m in \u001b[0;36minitialize_log\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0m_experiment_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_file_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_experiment_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: './talos_logs/talos_bigru_deep_log_test/061520020559.csv'"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"TALOS_BiGRU_DEEP_LOG_FILENAME = 'talos_logs/talos_bigru_deep_log'\\nif RUN_STATE == 'testing':\\n    TALOS_BiGRU_DEEP_LOG_FILENAME += '_test'\\n# talos_bigru_deep_log_pathname = os.path.join(TALOS_DIR, TALOS_BiGRU_DEEP_LOG_FILENAME)\\n\\nhistory_model = ta.Scan(model_data['x_train'],\\n                        model_data['y_train'],\\n                        x_val=model_data['x_train_dev'],\\n                        y_val=model_data['y_train_dev'],\\n                        model=load_bi_gru_model,\\n                        params=rnn_deep_gru_config,\\n                        fraction_limit=0.1,\\n                        print_params=True,\\n                        seed=(123),\\n                        experiment_name=TALOS_BiGRU_DEEP_LOG_FILENAME\\n                        )\";\n",
       "                var nbb_formatted_code = \"TALOS_BiGRU_DEEP_LOG_FILENAME = \\\"talos_logs/talos_bigru_deep_log\\\"\\nif RUN_STATE == \\\"testing\\\":\\n    TALOS_BiGRU_DEEP_LOG_FILENAME += \\\"_test\\\"\\n# talos_bigru_deep_log_pathname = os.path.join(TALOS_DIR, TALOS_BiGRU_DEEP_LOG_FILENAME)\\n\\nhistory_model = ta.Scan(\\n    model_data[\\\"x_train\\\"],\\n    model_data[\\\"y_train\\\"],\\n    x_val=model_data[\\\"x_train_dev\\\"],\\n    y_val=model_data[\\\"y_train_dev\\\"],\\n    model=load_bi_gru_model,\\n    params=rnn_deep_gru_config,\\n    fraction_limit=0.1,\\n    print_params=True,\\n    seed=(123),\\n    experiment_name=TALOS_BiGRU_DEEP_LOG_FILENAME,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TALOS_BiGRU_DEEP_LOG_FILENAME = 'talos_logs/talos_bigru_deep_log'\n",
    "if RUN_STATE == 'testing':\n",
    "    TALOS_BiGRU_DEEP_LOG_FILENAME += '_test'\n",
    "# talos_bigru_deep_log_pathname = os.path.join(TALOS_DIR, TALOS_BiGRU_DEEP_LOG_FILENAME)\n",
    "\n",
    "history_model = ta.Scan(model_data['x_train'],\n",
    "                        model_data['y_train'],\n",
    "                        x_val=model_data['x_train_dev'],\n",
    "                        y_val=model_data['y_train_dev'],\n",
    "                        model=load_bi_gru_model,\n",
    "                        params=rnn_deep_gru_config,\n",
    "                        fraction_limit=0.1,\n",
    "                        print_params=True,\n",
    "                        seed=(123),\n",
    "                        experiment_name=TALOS_BiGRU_DEEP_LOG_FILENAME\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Finds the best model configuration based for our RNN based on the highest value of the *val_f1*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'round_epochs': 3,\n",
       " 'val_loss': 0.1728040204445521,\n",
       " 'val_precision': 0.9533045596168155,\n",
       " 'val_recall': 0.933333333446866,\n",
       " 'val_f1': 0.9431521987915039,\n",
       " 'val_accuracy': 0.9625396849995568,\n",
       " 'val_categorical_accuracy': 0.9447619048754374,\n",
       " 'loss': 0.1799544942835156,\n",
       " 'precision': 0.947758856533336,\n",
       " 'recall': 0.9221768709104888,\n",
       " 'f1': 0.9346929049816262,\n",
       " 'accuracy': 0.957097516887042,\n",
       " 'categorical_accuracy': 0.9352380954002848,\n",
       " 'model_type': 'keras_deep_BiGRU_model',\n",
       " 'embedding_dim': 300,\n",
       " 'gru_size': 200,\n",
       " 'dense': 300,\n",
       " 'embeddings_matrix_path': 'embeddings-matrix-pickle',\n",
       " 'visualize_process': 'True',\n",
       " 'with_early_stoping': 'True',\n",
       " 'multistack_run': 'False',\n",
       " 'early_stopping': 'True',\n",
       " 'early_stopping_config__monitor': 'val_f1',\n",
       " 'early_stopping_config__min_delta': 0,\n",
       " 'early_stopping_config__patience': 5,\n",
       " 'early_stopping_config__mode': 'max',\n",
       " 'embeddings_dropout': 0.2,\n",
       " 'var_dropout': 0.2,\n",
       " 'mlp_dropout': 0.2,\n",
       " 'mlp_activation': 'softmax',\n",
       " 'rnn_activation': 'tanh',\n",
       " 'optimizer': 'Nadam',\n",
       " 'batch_size': 64,\n",
       " 'epochs': 3}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_talos = ta.Reporting(history_model)\n",
    "best_model_idx = report_talos.data['val_f1'].idxmax()\n",
    "best_model_params = report_talos.data.loc[best_model_idx].to_dict()\n",
    "best_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.models import (load_bi_gru_model, \n",
    "                        load_bi_lstm_model, \n",
    "                        find_best_model_over_scan_logs)\n",
    "\n",
    "TALOS_BiGRU_DEEP_LOG_FILENAME = 'talos_bigru_deep_log'\n",
    "talos_bigru_deep_log_pathname = os.path.join(TALOS_DIR, TALOS_BiGRU_DEEP_LOG_FILENAME)\n",
    "\n",
    "best_model_params = find_best_model_over_scan_logs('val_f1', *[talos_bigru_deep_log_pathname+ '_.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Train a new RNN model based on the best Talos configuration.\n",
    "\n",
    " ****Note: the below cells have been explicitly removed from the PRODUCTION run because they required an extra model generation which was demanding in terms of recources and time. For extra information about the PRODUCTION run check the README instructions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.int64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-025a48a6bbc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                              \u001b[0mmodel_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_train_dev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                              \u001b[0mmodel_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train_dev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                              best_model_params)\n\u001b[0m",
      "\u001b[0;32m~/master_classes/text_analytics/RNNTextAnalytics/app/models.py\u001b[0m in \u001b[0;36mload_bi_gru_model\u001b[0;34m(x_train, y_train, x_train_dev, y_train_dev, params)\u001b[0m\n\u001b[1;32m     83\u001b[0m     bi_gru = Bidirectional(GRU(GRU_SIZE,\n\u001b[1;32m     84\u001b[0m                                \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                                recurrent_dropout=params['var_dropout']))(drop_emb)\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmultistack_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# In Case of multistack  RNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    520\u001b[0m                                              initial_state=backward_state, **kwargs)\n\u001b[1;32m    521\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0my_rev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1647\u001b[0m                                      \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m                                      \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m                                      initial_state=initial_state)\n\u001b[0m\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m             raise ValueError('Layer has ' + str(len(self.states)) +\n\u001b[1;32m    607\u001b[0m                              \u001b[0;34m' states but was passed '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mstates\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m                 \u001b[0mnum_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m                 \u001b[0mnum_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.int64' has no len()"
     ]
    }
   ],
   "source": [
    "if RUN_STATE == 'testing':\n",
    "    # Train and Load the best model of given the tuned featured model\n",
    "    best_model_params['early_stopping'] = True\n",
    "    best_model_params['with_early_stopping'] = True\n",
    "    best_model_params['visualize_process'] = True\n",
    "    model_history, model = load_bi_gru_model(model_data['x_train'],\n",
    "                                             model_data['y_train'],\n",
    "                                             model_data['x_train_dev'],\n",
    "                                             model_data['y_train_dev'],\n",
    "                                             best_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model History Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if RUN_STATE == 'testing':\n",
    "    from app.visualization import plot_history_metrics\n",
    "    import matplotlib.pylab as plt\n",
    "\n",
    "    %matplotlib inline\n",
    "    plot_history_metrics(history_obj=model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance model\n",
    "\n",
    "Evaluates the performance of the best trained model in the **test** dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_STATE == 'testing':\n",
    "    score = model.evaluate(model_data_ftc['x_test'],\n",
    "                           model_data_ftc['y_test'],\n",
    "                           batch_size=best_model_params['batch_size'],\n",
    "                           verbose=1)\n",
    "\n",
    "    print('\\nTest f1: %.4f' % (score[1]))\n",
    "    print('\\nTest categorical accuracy: %.4f'% (score[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Prediction Perfomance  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_STATE == 'testing':\n",
    "    import numpy as np\n",
    "    from app.visualization import (plot_prediction_metrics,\n",
    "                                   create_clf_report,\n",
    "                                   plot_roc_curve,\n",
    "                                   plot_precision_recall_curve,\n",
    "                                   plot_confusion_matrix)\n",
    "    import matplotlib.pylab as plt\n",
    "\n",
    "    prediction_val = model.predict(model_data['x_test'], batch_size=best_model_params['batch_size'])\n",
    "\n",
    "    # returns each entry result to the classification with the relevant probabilities\n",
    "    y_pred_processed = np.array([np.argmax(val) for val in prediction_val])\n",
    "    y_true_processed = np.array([np.argmax(val) for val in model_data['y_test']])\n",
    "\n",
    "    # If you want to see the OneVSAll ROC Curves of each class uncomment the below line\n",
    "    # plot_roc_curve(model_data['y_test'], prediction_val, Classes, 1)\n",
    "\n",
    "    # If you want to see the OneVSAll Precission Recall Curves of each class, comment out the below line\n",
    "    # plot_precision_recall_curve(model_data['y_test'], prediction_val, Classes , 1)\n",
    "\n",
    "    # If you want to get the Classification Report, comment out the below line\n",
    "    create_clf_report(model_data['y_test'], (prediction_val > 0.5).astype('int32'),\n",
    "                      y_true_processed, y_pred_processed)\n",
    "\n",
    "    # If you want to get the confusion matrix,comment out the below line\n",
    "    plot_confusion_matrix(y_true_processed, y_pred_processed, Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multistack RNN with BiGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TALOS_BiGRU_DEEP_MUTLI_LOG_FILENAME = 'talos_bigru_deep_multi_log'\n",
    "if RUN_STATE == 'testing':\n",
    "    TALOS_BiGRU_DEEP_MUTLI_LOG_FILENAME += '_test'\n",
    "talos_bigru_deep_multi_log_pathname = os.path.join(TALOS_DIR, TALOS_BiGRU_DEEP_MUTLI_LOG_FILENAME)\n",
    "\n",
    "\n",
    "###### Production configuration\n",
    "rnn_deep_gru_multi_config = rnn_deep_gru_config.copy()\n",
    "rnn_deep_gru_multi_config.update({\n",
    "    \"model_type\": [\"keras_deep_BiGRU_multi_model\"],\n",
    "    \"multistack_run\": [True],\n",
    "})\n",
    "\n",
    "history_model_multi = ta.Scan(model_data['x_train'],\n",
    "                        model_data['y_train'],\n",
    "                        x_val=model_data['x_train_dev'],\n",
    "                        y_val=model_data['y_train_dev'],\n",
    "                        model=load_bi_gru_model,\n",
    "                        params=rnn_deep_gru_multi_config,\n",
    "                        grid_downsample=0.1,\n",
    "                        print_params=True,\n",
    "                        last_epoch_value=True,\n",
    "                        seed=(123),\n",
    "                        dataset_name=talos_bigru_deep_multi_log_pathname\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Finds the best model configuration based for our RNN based on the highest value of the *val_f1*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_talos_multi = ta.Reporting(history_model_multi)\n",
    "best_model_idx = report_talos_multi.data['val_f1'].idxmax()\n",
    "best_model_params_multi = report_talos_multi.data.loc[best_model_idx].to_dict()\n",
    "best_model_params_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Train a new RNN model based on the best Talos configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_STATE == 'testing':\n",
    "    # Train and Load the best model of given the tuned featured model\n",
    "    model_history_multi, model_multi = load_bi_gru_model(model_data['x_train'],\n",
    "                                                         model_data['y_train'],\n",
    "                                                         model_data['x_train_dev'],\n",
    "                                                         model_data['y_train_dev'],\n",
    "                                                         best_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model History Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if RUN_STATE == 'testing':\n",
    "    from app.visualization import plot_history_metrics\n",
    "    import matplotlib.pylab as plt\n",
    "\n",
    "    %matplotlib inline\n",
    "    plot_history_metrics(history_obj=model_history_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance model\n",
    "\n",
    "Evaluates the performance of the best trained model in the **test** dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_STATE == 'testing':\n",
    "    score_multi = model_multi.evaluate(model_data['x_test'],\n",
    "                                       model_data['y_test'],\n",
    "                                       batch_size=best_model_params_multi['batch_size'],\n",
    "                                       verbose=1)\n",
    "\n",
    "    print('\\nTest f1: %.4f' % (score_multi[1]))\n",
    "    print('\\nTest categorical accuracy: %.4f'% (score_multi[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Prediction Perfomance  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_STATE == 'testing':\n",
    "    import numpy as np\n",
    "    from app.visualization import (plot_prediction_metrics,\n",
    "                                   create_clf_report,\n",
    "                                   plot_roc_curve,\n",
    "                                   plot_precision_recall_curve,\n",
    "                                   plot_confusion_matrix)\n",
    "    import matplotlib.pylab as plt\n",
    "\n",
    "    prediction_val_multi = model_multi.predict(model_data['x_test'], batch_size=best_model_params['batch_size'])\n",
    "\n",
    "    # returns each entry result to the classification with the relevant probabilities\n",
    "    y_pred_processed_multi = np.array([np.argmax(val) for val in prediction_val_multi])\n",
    "    y_true_processed_multi = np.array([np.argmax(val) for val in model_data['y_test']])\n",
    "\n",
    "    # If you want to see the OneVSAll ROC Curves of each class uncomment the below line\n",
    "    # plot_roc_curve(model_data['y_test'], prediction_val, Classes, 1)\n",
    "\n",
    "    # If you want to see the OneVSAll Precission Recall Curves of each class, comment out the below line\n",
    "    # plot_precision_recall_curve(model_data['y_test'], prediction_val, Classes , 1)\n",
    "\n",
    "    # If you want to get the Classification Report, comment out the below line\n",
    "    create_clf_report(model_data['y_test'], (prediction_val_multi > 0.5).astype('int32'),\n",
    "                      y_true_processed_multi, y_pred_processed_multi)\n",
    "\n",
    "    # If you want to get the confusion matrix,comment out the below line\n",
    "    plot_confusion_matrix(y_true_processed_multi, y_pred_processed_multi, Classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}