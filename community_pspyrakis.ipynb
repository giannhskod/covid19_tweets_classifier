{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import community as community_louvain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the retweet network as a directed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 784898\n",
      "Number of edges: 7401920\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_weighted_edgelist(\"data/retweet_weighted.edgelist\", create_using=nx.DiGraph(), nodetype=int)\n",
    "\n",
    "print(\"Number of nodes:\", G.number_of_nodes())\n",
    "print(\"Number of edges:\", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the ID of the user that posted each message, and initialize for each user a 15-dimensional vector that will store the number of messages of each class posted by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "posted_by = dict()\n",
    "posts_per_class = dict()\n",
    "users = list()\n",
    "with open('data/posts.tsv', 'r') as f:\n",
    "    for line in f:\n",
    "        t = line.split('\\t')\n",
    "        posted_by[int(t[0])] = int(t[1])\n",
    "        posts_per_class[int(t[1])] = np.zeros(15)\n",
    "        users.append(int(t[1]))\n",
    "users = set(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training data. Given a message posted by user A that belongs to class B, increase the number of posts of class B posted by user A by 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = list()\n",
    "y_train = list()    \n",
    "with open('data/train.csv', 'r') as f:\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        train_index.append(int(t[0]))\n",
    "        y_train.append(int(t[1]))\n",
    "        posts_per_class[posted_by[int(t[0])]][int(t[1][:-1])] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = list()  \n",
    "with open('data/test.csv', 'r') as f:\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        test_index.append(int(t[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_un = G.copy().to_undirected()\n",
    "for node in G:\n",
    "    for ngbr in nx.neighbors(G, node):\n",
    "        if node in nx.neighbors(G, ngbr):\n",
    "            G_un.edges[node, ngbr]['weight'] = (\n",
    "                G.edges[node, ngbr]['weight'] + G.edges[ngbr, node]['weight']\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 7401920\n",
      "Number of undirected edges: 7383985\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of edges:\", G.number_of_edges())\n",
    "print(\"Number of undirected edges:\", G_un.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_partition = dict()\n",
    "for user in G.nodes():\n",
    "    initial_partition[user] = -1\n",
    "    has_succ = False\n",
    "    has_pred = False\n",
    "    succ_posts_per_class = np.zeros((1, 15))\n",
    "    pred_posts_per_class = np.zeros((1, 15))\n",
    "    for successor in G.successors(user):\n",
    "        if successor in posts_per_class:\n",
    "            has_succ = True\n",
    "            succ_posts_per_class[0,:15] += posts_per_class[successor]\n",
    "    for predecessor in G.predecessors(user):\n",
    "        if predecessor in posts_per_class:\n",
    "            has_pred = True\n",
    "            pred_posts_per_class[0,:15] += posts_per_class[predecessor]\n",
    "\n",
    "    if user in posts_per_class:\n",
    "        initial_partition[user] = posts_per_class[user].tolist().index(max(posts_per_class[user]))\n",
    "    elif has_pred:\n",
    "        maxValue = np.max(pred_posts_per_class)\n",
    "        index_of_maximum = (np.where(pred_posts_per_class[0] == maxValue)[0])[0]\n",
    "        if(user%2 == 0):\n",
    "            initial_partition[user] = index_of_maximum+15\n",
    "        else:\n",
    "            initial_partition[user] = index_of_maximum+30\n",
    "    elif has_succ:\n",
    "        maxValue = np.max(succ_posts_per_class)\n",
    "        index_of_maximum = (np.where(succ_posts_per_class[0] == maxValue)[0])[0]\n",
    "        if(user%2 == 0):\n",
    "            initial_partition[user] = index_of_maximum+45\n",
    "        else:\n",
    "            initial_partition[user] = index_of_maximum+60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 has occurred 6994 times\n",
      "1 has occurred 458 times\n",
      "2 has occurred 1855 times\n",
      "3 has occurred 811 times\n",
      "4 has occurred 829 times\n",
      "5 has occurred 105 times\n",
      "6 has occurred 78 times\n",
      "7 has occurred 14 times\n",
      "8 has occurred 75 times\n",
      "9 has occurred 94 times\n",
      "10 has occurred 416 times\n",
      "11 has occurred 230 times\n",
      "12 has occurred 246 times\n",
      "13 has occurred 143 times\n",
      "14 has occurred 292 times\n",
      "15 has occurred 6842 times\n",
      "16 has occurred 1137 times\n",
      "17 has occurred 4217 times\n",
      "18 has occurred 537 times\n",
      "19 has occurred 1374 times\n",
      "20 has occurred 109 times\n",
      "21 has occurred 189 times\n",
      "22 has occurred 14 times\n",
      "23 has occurred 59 times\n",
      "24 has occurred 256 times\n",
      "25 has occurred 609 times\n",
      "26 has occurred 390 times\n",
      "27 has occurred 482 times\n",
      "28 has occurred 103 times\n",
      "29 has occurred 212 times\n",
      "30 has occurred 6938 times\n",
      "31 has occurred 1156 times\n",
      "32 has occurred 4097 times\n",
      "33 has occurred 533 times\n",
      "34 has occurred 1369 times\n",
      "35 has occurred 100 times\n",
      "36 has occurred 194 times\n",
      "37 has occurred 12 times\n",
      "38 has occurred 45 times\n",
      "39 has occurred 247 times\n",
      "40 has occurred 640 times\n",
      "41 has occurred 405 times\n",
      "42 has occurred 453 times\n",
      "43 has occurred 108 times\n",
      "44 has occurred 208 times\n",
      "45 has occurred 177319 times\n",
      "46 has occurred 35979 times\n",
      "47 has occurred 66371 times\n",
      "48 has occurred 51045 times\n",
      "49 has occurred 11392 times\n",
      "50 has occurred 2012 times\n",
      "51 has occurred 2212 times\n",
      "52 has occurred 126 times\n",
      "53 has occurred 1042 times\n",
      "54 has occurred 1094 times\n",
      "55 has occurred 7016 times\n",
      "56 has occurred 9053 times\n",
      "57 has occurred 2737 times\n",
      "58 has occurred 485 times\n",
      "59 has occurred 1691 times\n",
      "60 has occurred 177413 times\n",
      "61 has occurred 35981 times\n",
      "62 has occurred 66271 times\n",
      "63 has occurred 50879 times\n",
      "64 has occurred 11575 times\n",
      "65 has occurred 1966 times\n",
      "66 has occurred 2264 times\n",
      "67 has occurred 138 times\n",
      "68 has occurred 1036 times\n",
      "69 has occurred 1154 times\n",
      "70 has occurred 7028 times\n",
      "71 has occurred 9160 times\n",
      "72 has occurred 2599 times\n",
      "73 has occurred 472 times\n",
      "74 has occurred 1713 times\n"
     ]
    }
   ],
   "source": [
    "for comm in set(initial_partition.values()):\n",
    "    times = list(initial_partition.values()).count(comm)\n",
    "    print('{} has occurred {} times'.format(comm, times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the best partition\n",
    "partition = community_louvain.best_partition(G_un,resolution = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 has occurred 88338 times\n",
      "1 has occurred 92569 times\n",
      "2 has occurred 117290 times\n",
      "3 has occurred 127860 times\n",
      "4 has occurred 84665 times\n",
      "5 has occurred 145582 times\n",
      "6 has occurred 17908 times\n",
      "7 has occurred 21268 times\n",
      "8 has occurred 22571 times\n",
      "9 has occurred 4716 times\n",
      "10 has occurred 6870 times\n",
      "11 has occurred 3887 times\n",
      "12 has occurred 15943 times\n",
      "13 has occurred 762 times\n",
      "14 has occurred 22999 times\n",
      "15 has occurred 610 times\n",
      "16 has occurred 1 times\n",
      "17 has occurred 3029 times\n",
      "18 has occurred 5 times\n",
      "19 has occurred 2 times\n",
      "20 has occurred 1 times\n",
      "21 has occurred 45 times\n",
      "22 has occurred 385 times\n",
      "23 has occurred 562 times\n",
      "24 has occurred 426 times\n",
      "25 has occurred 1 times\n",
      "26 has occurred 1 times\n",
      "27 has occurred 3 times\n",
      "28 has occurred 2 times\n",
      "29 has occurred 800 times\n",
      "30 has occurred 4 times\n",
      "31 has occurred 2 times\n",
      "32 has occurred 2 times\n",
      "33 has occurred 653 times\n",
      "34 has occurred 4 times\n",
      "35 has occurred 4 times\n",
      "36 has occurred 1 times\n",
      "37 has occurred 6 times\n",
      "38 has occurred 1 times\n",
      "39 has occurred 16 times\n",
      "40 has occurred 15 times\n",
      "41 has occurred 23 times\n",
      "42 has occurred 17 times\n",
      "43 has occurred 279 times\n",
      "44 has occurred 6 times\n",
      "45 has occurred 20 times\n",
      "46 has occurred 18 times\n",
      "47 has occurred 111 times\n",
      "48 has occurred 686 times\n",
      "49 has occurred 626 times\n",
      "50 has occurred 75 times\n",
      "51 has occurred 11 times\n",
      "52 has occurred 2 times\n",
      "53 has occurred 6 times\n",
      "54 has occurred 503 times\n",
      "55 has occurred 24 times\n",
      "56 has occurred 31 times\n",
      "57 has occurred 10 times\n",
      "58 has occurred 1 times\n",
      "59 has occurred 82 times\n",
      "60 has occurred 228 times\n",
      "61 has occurred 11 times\n",
      "62 has occurred 2 times\n",
      "63 has occurred 201 times\n",
      "64 has occurred 4 times\n",
      "65 has occurred 3 times\n",
      "66 has occurred 8 times\n",
      "67 has occurred 1 times\n",
      "68 has occurred 110 times\n",
      "69 has occurred 64 times\n",
      "70 has occurred 5 times\n",
      "71 has occurred 36 times\n",
      "72 has occurred 58 times\n",
      "73 has occurred 104 times\n",
      "74 has occurred 6 times\n",
      "75 has occurred 11 times\n",
      "76 has occurred 7 times\n",
      "77 has occurred 3 times\n",
      "78 has occurred 2 times\n",
      "79 has occurred 44 times\n",
      "80 has occurred 4 times\n",
      "81 has occurred 2 times\n",
      "82 has occurred 23 times\n",
      "83 has occurred 2 times\n",
      "84 has occurred 22 times\n",
      "85 has occurred 5 times\n",
      "86 has occurred 2 times\n",
      "87 has occurred 35 times\n",
      "88 has occurred 2 times\n",
      "89 has occurred 41 times\n",
      "90 has occurred 7 times\n",
      "91 has occurred 1 times\n",
      "92 has occurred 3 times\n",
      "93 has occurred 14 times\n",
      "94 has occurred 8 times\n",
      "95 has occurred 20 times\n",
      "96 has occurred 4 times\n",
      "97 has occurred 4 times\n",
      "98 has occurred 17 times\n",
      "99 has occurred 19 times\n",
      "100 has occurred 34 times\n",
      "101 has occurred 36 times\n",
      "102 has occurred 3 times\n",
      "103 has occurred 1 times\n",
      "104 has occurred 5 times\n",
      "105 has occurred 1 times\n",
      "106 has occurred 2 times\n",
      "107 has occurred 6 times\n",
      "108 has occurred 8 times\n",
      "109 has occurred 20 times\n",
      "110 has occurred 1 times\n",
      "111 has occurred 6 times\n",
      "112 has occurred 17 times\n",
      "113 has occurred 16 times\n",
      "114 has occurred 7 times\n",
      "115 has occurred 2 times\n",
      "116 has occurred 23 times\n",
      "117 has occurred 3 times\n",
      "118 has occurred 46 times\n",
      "119 has occurred 4 times\n",
      "120 has occurred 13 times\n",
      "121 has occurred 11 times\n",
      "122 has occurred 12 times\n",
      "123 has occurred 14 times\n",
      "124 has occurred 1 times\n",
      "125 has occurred 15 times\n",
      "126 has occurred 1 times\n",
      "127 has occurred 8 times\n",
      "128 has occurred 1 times\n",
      "129 has occurred 41 times\n",
      "130 has occurred 5 times\n",
      "131 has occurred 4 times\n",
      "132 has occurred 24 times\n",
      "133 has occurred 4 times\n",
      "134 has occurred 4 times\n",
      "135 has occurred 14 times\n",
      "136 has occurred 3 times\n",
      "137 has occurred 13 times\n",
      "138 has occurred 3 times\n",
      "139 has occurred 5 times\n",
      "140 has occurred 6 times\n",
      "141 has occurred 13 times\n",
      "142 has occurred 27 times\n",
      "143 has occurred 2 times\n",
      "144 has occurred 13 times\n",
      "145 has occurred 22 times\n",
      "146 has occurred 6 times\n",
      "147 has occurred 3 times\n",
      "148 has occurred 6 times\n",
      "149 has occurred 2 times\n",
      "150 has occurred 2 times\n",
      "151 has occurred 1 times\n",
      "152 has occurred 12 times\n",
      "153 has occurred 1 times\n",
      "154 has occurred 2 times\n",
      "155 has occurred 4 times\n",
      "156 has occurred 2 times\n",
      "157 has occurred 3 times\n",
      "158 has occurred 6 times\n",
      "159 has occurred 2 times\n",
      "160 has occurred 2 times\n",
      "161 has occurred 7 times\n",
      "162 has occurred 7 times\n",
      "163 has occurred 1 times\n",
      "164 has occurred 10 times\n",
      "165 has occurred 7 times\n",
      "166 has occurred 2 times\n",
      "167 has occurred 8 times\n",
      "168 has occurred 12 times\n",
      "169 has occurred 4 times\n",
      "170 has occurred 4 times\n",
      "171 has occurred 3 times\n",
      "172 has occurred 8 times\n",
      "173 has occurred 9 times\n",
      "174 has occurred 2 times\n",
      "175 has occurred 1 times\n",
      "176 has occurred 2 times\n",
      "177 has occurred 2 times\n",
      "178 has occurred 13 times\n",
      "179 has occurred 32 times\n",
      "180 has occurred 10 times\n",
      "181 has occurred 6 times\n",
      "182 has occurred 7 times\n",
      "183 has occurred 5 times\n",
      "184 has occurred 14 times\n",
      "185 has occurred 6 times\n",
      "186 has occurred 4 times\n",
      "187 has occurred 1 times\n",
      "188 has occurred 13 times\n",
      "189 has occurred 2 times\n",
      "190 has occurred 2 times\n",
      "191 has occurred 1 times\n",
      "192 has occurred 3 times\n",
      "193 has occurred 14 times\n",
      "194 has occurred 5 times\n",
      "195 has occurred 7 times\n",
      "196 has occurred 2 times\n",
      "197 has occurred 10 times\n",
      "198 has occurred 4 times\n",
      "199 has occurred 1 times\n",
      "200 has occurred 2 times\n",
      "201 has occurred 2 times\n",
      "202 has occurred 2 times\n",
      "203 has occurred 1 times\n",
      "204 has occurred 2 times\n",
      "205 has occurred 6 times\n",
      "206 has occurred 9 times\n",
      "207 has occurred 1 times\n",
      "208 has occurred 2 times\n",
      "209 has occurred 6 times\n",
      "210 has occurred 6 times\n",
      "211 has occurred 6 times\n",
      "212 has occurred 7 times\n",
      "213 has occurred 4 times\n",
      "214 has occurred 2 times\n",
      "215 has occurred 2 times\n",
      "216 has occurred 11 times\n",
      "217 has occurred 2 times\n",
      "218 has occurred 2 times\n",
      "219 has occurred 14 times\n",
      "220 has occurred 1 times\n",
      "221 has occurred 8 times\n",
      "222 has occurred 2 times\n",
      "223 has occurred 7 times\n",
      "224 has occurred 4 times\n",
      "225 has occurred 7 times\n",
      "226 has occurred 1 times\n",
      "227 has occurred 17 times\n",
      "228 has occurred 2 times\n",
      "229 has occurred 6 times\n",
      "230 has occurred 3 times\n",
      "231 has occurred 2 times\n",
      "232 has occurred 1 times\n",
      "233 has occurred 3 times\n",
      "234 has occurred 3 times\n",
      "235 has occurred 4 times\n",
      "236 has occurred 5 times\n",
      "237 has occurred 4 times\n",
      "238 has occurred 6 times\n",
      "239 has occurred 5 times\n",
      "240 has occurred 7 times\n",
      "241 has occurred 1 times\n",
      "242 has occurred 4 times\n",
      "243 has occurred 2 times\n",
      "244 has occurred 7 times\n",
      "245 has occurred 3 times\n",
      "246 has occurred 11 times\n",
      "247 has occurred 3 times\n",
      "248 has occurred 3 times\n",
      "249 has occurred 2 times\n",
      "250 has occurred 3 times\n",
      "251 has occurred 1 times\n",
      "252 has occurred 7 times\n",
      "253 has occurred 3 times\n",
      "254 has occurred 3 times\n",
      "255 has occurred 1 times\n",
      "256 has occurred 1 times\n",
      "257 has occurred 2 times\n",
      "258 has occurred 1 times\n",
      "259 has occurred 1 times\n",
      "260 has occurred 4 times\n",
      "261 has occurred 5 times\n",
      "262 has occurred 3 times\n",
      "263 has occurred 10 times\n",
      "264 has occurred 3 times\n",
      "265 has occurred 2 times\n",
      "266 has occurred 3 times\n",
      "267 has occurred 2 times\n",
      "268 has occurred 2 times\n",
      "269 has occurred 5 times\n",
      "270 has occurred 2 times\n",
      "271 has occurred 2 times\n",
      "272 has occurred 8 times\n",
      "273 has occurred 7 times\n",
      "274 has occurred 5 times\n",
      "275 has occurred 2 times\n",
      "276 has occurred 7 times\n",
      "277 has occurred 2 times\n",
      "278 has occurred 3 times\n",
      "279 has occurred 1 times\n",
      "280 has occurred 2 times\n",
      "281 has occurred 1 times\n",
      "282 has occurred 1 times\n",
      "283 has occurred 1 times\n",
      "284 has occurred 4 times\n",
      "285 has occurred 1 times\n",
      "286 has occurred 8 times\n",
      "287 has occurred 3 times\n",
      "288 has occurred 2 times\n",
      "289 has occurred 3 times\n",
      "290 has occurred 7 times\n",
      "291 has occurred 2 times\n",
      "292 has occurred 3 times\n",
      "293 has occurred 2 times\n",
      "294 has occurred 2 times\n",
      "295 has occurred 3 times\n",
      "296 has occurred 2 times\n",
      "297 has occurred 4 times\n",
      "298 has occurred 3 times\n",
      "299 has occurred 2 times\n",
      "300 has occurred 3 times\n",
      "301 has occurred 3 times\n",
      "302 has occurred 4 times\n",
      "303 has occurred 2 times\n",
      "304 has occurred 4 times\n",
      "305 has occurred 4 times\n",
      "306 has occurred 2 times\n",
      "307 has occurred 1 times\n",
      "308 has occurred 2 times\n",
      "309 has occurred 2 times\n",
      "310 has occurred 3 times\n",
      "311 has occurred 8 times\n",
      "312 has occurred 3 times\n",
      "313 has occurred 11 times\n",
      "314 has occurred 2 times\n",
      "315 has occurred 2 times\n",
      "316 has occurred 3 times\n",
      "317 has occurred 2 times\n",
      "318 has occurred 1 times\n",
      "319 has occurred 4 times\n",
      "320 has occurred 2 times\n",
      "321 has occurred 1 times\n",
      "322 has occurred 2 times\n",
      "323 has occurred 3 times\n",
      "324 has occurred 2 times\n",
      "325 has occurred 4 times\n",
      "326 has occurred 2 times\n",
      "327 has occurred 2 times\n",
      "328 has occurred 2 times\n",
      "329 has occurred 1 times\n",
      "330 has occurred 2 times\n",
      "331 has occurred 2 times\n",
      "332 has occurred 4 times\n",
      "333 has occurred 4 times\n",
      "334 has occurred 2 times\n",
      "335 has occurred 1 times\n",
      "336 has occurred 3 times\n",
      "337 has occurred 8 times\n",
      "338 has occurred 2 times\n",
      "339 has occurred 1 times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340 has occurred 2 times\n",
      "341 has occurred 2 times\n",
      "342 has occurred 1 times\n",
      "343 has occurred 7 times\n",
      "344 has occurred 3 times\n",
      "345 has occurred 5 times\n",
      "346 has occurred 7 times\n",
      "347 has occurred 2 times\n",
      "348 has occurred 2 times\n",
      "349 has occurred 6 times\n",
      "350 has occurred 1 times\n",
      "351 has occurred 3 times\n",
      "352 has occurred 2 times\n",
      "353 has occurred 1 times\n",
      "354 has occurred 3 times\n",
      "355 has occurred 1 times\n",
      "356 has occurred 2 times\n",
      "357 has occurred 2 times\n",
      "358 has occurred 2 times\n",
      "359 has occurred 2 times\n",
      "360 has occurred 2 times\n",
      "361 has occurred 2 times\n",
      "362 has occurred 2 times\n",
      "363 has occurred 2 times\n",
      "364 has occurred 1 times\n",
      "365 has occurred 1 times\n",
      "366 has occurred 3 times\n",
      "367 has occurred 2 times\n",
      "368 has occurred 2 times\n",
      "369 has occurred 1 times\n",
      "370 has occurred 2 times\n",
      "371 has occurred 3 times\n",
      "372 has occurred 2 times\n",
      "373 has occurred 1 times\n",
      "374 has occurred 1 times\n",
      "375 has occurred 1 times\n",
      "376 has occurred 2 times\n",
      "377 has occurred 1 times\n",
      "378 has occurred 2 times\n",
      "379 has occurred 2 times\n",
      "380 has occurred 2 times\n",
      "381 has occurred 1 times\n"
     ]
    }
   ],
   "source": [
    "for comm in set(partition.values()):\n",
    "    times = list(partition.values()).count(comm)\n",
    "    print('{} has occurred {} times'.format(comm, times))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the posibility of each class per community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_per_comm = np.zeros((len(set(partition.values())), 15))\n",
    "pos_per_comm = np.zeros((len(set(partition.values())), 15))\n",
    "for i,idx in enumerate(train_index):\n",
    "    community = partition[posted_by[idx]]\n",
    "    items_per_comm[community,:15] += posts_per_class[posted_by[idx]]\n",
    "pos_per_comm = items_per_comm\n",
    "for i in range(0,len(pos_per_comm)):   \n",
    "    if np.sum(items_per_comm[i,:15]) > 0:\n",
    "        pos_per_comm[i,:15] /= np.sum(items_per_comm[i,:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Create the training matrix. Each row corresponds to a message. Use the following 15-dimensional vector of the user that posted the message and concatenate to that vector the following three features:<br/>(1) in-degree of user <br/> (2) out-degree of user <br/> (3) community user belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(train_index), 17))\n",
    "for i,idx in enumerate(train_index):\n",
    "    for successor in G.successors(posted_by[idx]):\n",
    "        if partition[successor] == partition[posted_by[idx]]:\n",
    "            if successor in posts_per_class:\n",
    "                X_train[i,:15] += posts_per_class[successor]\n",
    "    \n",
    "    for predecessor in G.predecessors(posted_by[idx]):\n",
    "        if partition[predecessor] == partition[posted_by[idx]]:\n",
    "            if predecessor in posts_per_class:\n",
    "                X_train[i,:15] += posts_per_class[predecessor]\n",
    "    if np.sum(X_train[i,:15]) > 0:\n",
    "        X_train[i,:15] /= np.sum(X_train[i,:15])\n",
    "    \n",
    "    X_train[i,15] = G_un.degree(posted_by[idx])\n",
    "    X_train[i,16] = partition[posted_by[idx]]\n",
    "X_train_dev, X_test_dev, y_train_dev, y_test_dev = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the test matrix. Each row corresponds to a message.Use the following 15-dimensional vector of the user that posted the message and concatenate to that vector the following three features: <br/>(1) in-degree of user<br/>(2) out-degree of user <br/> (3) community user belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((len(test_index), 17))\n",
    "for i,idx in enumerate(test_index):\n",
    "    for successor in G.successors(posted_by[idx]):\n",
    "        if partition[successor] == partition[posted_by[idx]]:\n",
    "            if successor in posts_per_class:\n",
    "                X_test[i,:15] += posts_per_class[successor]\n",
    "    \n",
    "    for predecessor in G.predecessors(posted_by[idx]):\n",
    "        if partition[predecessor] == partition[posted_by[idx]]:\n",
    "            if predecessor in posts_per_class:\n",
    "                X_test[i,:15] += posts_per_class[predecessor]\n",
    "\n",
    "    if np.sum(X_test[i,:15]) > 0:\n",
    "        X_test[i,:15] /= np.sum(X_test[i,:15])\n",
    "\n",
    "    X_test[i,15] = G_un.degree(posted_by[idx])\n",
    "    X_test[i,16] = partition[posted_by[idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use logistic regression to classify the messages of the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pspyrakis/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='newton-cg', multi_class='auto')\n",
    "clf.fit(X_train_dev, y_train_dev)\n",
    "y_pred_lin = clf.predict_proba(X_test_dev)\n",
    "y_pred_dev_lin = clf.predict_proba(X_test_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss lin: 1.463698147182245\n"
     ]
    }
   ],
   "source": [
    "log = log_loss(y_test_dev,y_pred_dev_lin)\n",
    "print(\"log loss lin:\", log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto',probability = True,class_weight='balanced'))\n",
    "clf.fit(X_train_dev, y_train_dev)\n",
    "y_pred = clf.predict_proba(X_test_dev)\n",
    "y_pred_dev_SVC = clf.predict_proba(X_test_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss SVC: 1.5523828361712857\n"
     ]
    }
   ],
   "source": [
    "log = log_loss(y_test_dev,y_pred_dev_SVC)\n",
    "print(\"log loss SVC:\", log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=12,criterion = 'entropy')\n",
    "clf.fit(X_train_dev, y_train_dev)\n",
    "y_pred = clf.predict_proba(X_test_dev)\n",
    "y_pred_dev_Forest = clf.predict_proba(X_test_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss forest: 1.2279791094057024\n"
     ]
    }
   ],
   "source": [
    "log = log_loss(y_test_dev,y_pred_dev_Forest)\n",
    "print(\"log loss forest:\", log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf = make_pipeline(StandardScaler(),\n",
    "                          SGDClassifier(tol=1e-6,\n",
    "                                        loss = 'log',\n",
    "                                        eta0 = 0.0001,\n",
    "                                        learning_rate = 'adaptive'))\n",
    "clf.fit(X_train_dev, y_train_dev)\n",
    "y_pred = clf.predict_proba(X_test_dev)\n",
    "y_pred_dev_SGD = clf.predict_proba(X_test_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss SGD: 1.4543472769046584\n"
     ]
    }
   ],
   "source": [
    "log = log_loss(y_test_dev,y_pred_dev_SGD)\n",
    "print(\"log loss SGD:\", log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write predictions to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_so_far.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    lst = ['id']\n",
    "    for i in range(15):\n",
    "        lst.append('class_'+str(i))\n",
    "    writer.writerow(lst)\n",
    "    for i,idx in enumerate(test_index):\n",
    "        lst = y_pred[i,:].tolist()\n",
    "        lst.insert(0, idx)\n",
    "        writer.writerow(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community Detection2\n",
    "#### Girvan Newman method which takes a lot of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_to_remove(graph):\n",
    "  G_dict = nx.edge_betweenness_centrality(graph)\n",
    "  edge = ()\n",
    "\n",
    "  # extract the edge with highest edge betweenness centrality score\n",
    "  for key, value in sorted(G_dict.items(), key=lambda item: item[1], reverse = True):\n",
    "      edge = key\n",
    "      break\n",
    "\n",
    "  return edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def girvan_newman(graph):\n",
    "    # find number of connected components\n",
    "    sg = nx.connected_components(graph)\n",
    "    sg_count = nx.number_connected_components(graph)\n",
    "\n",
    "    while(sg_count == 1):\n",
    "        graph.remove_edge(edge_to_remove(graph)[0], edge_to_remove(graph)[1])\n",
    "        sg = nx.connected_components(graph)\n",
    "        sg_count = nx.number_connected_components(graph)\n",
    "\n",
    "    return sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find communities in the graph\n",
    "c = girvan_newman(G_un.copy())\n",
    "\n",
    "# find the nodes forming the communities\n",
    "node_groups = []\n",
    "\n",
    "for i in c:\n",
    "  node_groups.append(list(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
